虽然线程池能大大提高服务器的并发性能，但使用它也会存在一定风险。与所有多线程应用程序一样，用线程池构建的应用程序容易产生各种并发问题，如对共享资源的竞争和死锁。此外，如果线程池本身的实现不健壮，或者没有合理地使用线程池，还容易导致与线程池有关的死锁、系统资源不足和线程泄漏等问题。

1．死锁
任何多线程应用程序都有死锁风险。造成死锁的最简单的情形是，线程A持有对象X的锁，并且在等待对象Y的锁，而线程B持有对象Y的锁，并且在等待对象X的锁。线程A与线程B都不释放自己持有的锁，并且等待对方的锁，这就导致两个线程永远等待下去，死锁就这样产生了。
虽然任何多线程程序都有死锁的风险，但线程池还会导致另外一种死锁。在这种情形下，假定线程池中的所有工作线程都在执行各自任务时被阻塞，它们都在等待某个任务A的执行结果。而任务A依然在工作队列中，由于没有空闲线程，使得任务A一直不能被执行。这使得线程池中的所有工作线程都永远阻塞下去，死锁就这样产生了。
2．系统资源不足
如果线程池中的线程数目非常多，这些线程会消耗包括内存和其他系统资源在内的大量资源，从而严重影响系统性能。
3．并发错误
线程池的工作队列依靠wait()和notify()方法来使工作线程及时取得任务，但这两个方法都难于使用。如果编码不正确，可能会丢失通知，导致工作线程一直保持空闲状态，无视工作队列中需要处理的任务。因此使用这些方法时，必须格外小心，即便是专家也可能在这方面出错。最好使用现有的、比较成熟的线程池。例如，直接使用java.util.concurrent包中的线程池类。
4．线程泄漏
使用线程池的一个严重风险是线程泄漏。对于工作线程数目固定的线程池，如果工作线程在执行任务时抛出 RuntimeException 或Error，并且这些异常或错误没有被捕获，那么这个工作线程就会异常终止，使得线程池永久失去了一个工作线程。如果所有的工作线程都异常终止，线程池就最终变为空，没有任何可用的工作线程来处理任务。
导致线程泄漏的另一种情形是，工作线程在执行一个任务时被阻塞，如等待用户的输入数据，但是由于用户一直不输入数据（可能是因为用户走开了），导致这个工作线程一直被阻塞。这样的工作线程名存实亡，它实际上不执行任何任务了。假如线程池中所有的工作线程都处于这样的阻塞状态，那么线程池就无法处理新加入的任务了。
5．任务过载
当工作队列中有大量排队等候执行的任务时，这些任务本身可能会消耗太多的系统资源而引起系统资源缺乏。

综上所述，线程池可能会带来种种风险，为了尽可能避免它们，使用线程池时需要遵循以下原则。
（1）如果任务A在执行过程中需要同步等待任务B的执行结果，那么任务A不适合加入到线程池的工作队列中。如果把像任务A一样的需要等待其他任务执行结果的任务加入到工作队列中，可能会导致线程池的死锁。
（2）如果执行某个任务时可能会阻塞，并且是长时间的阻塞，则应该设定超时时间，避免工作线程永久的阻塞下去而导致线程泄漏。在服务器程序中，当线程等待客户连接，或者等待客户发送的数据时，都可能会阻塞。可以通过以下方式设定超时时间：
 调用ServerSocket的setSoTimeout(int timeout)方法，设定等待客户连接的超时时间
（3）了解任务的特点，分析任务是执行经常会阻塞的I/O操作，还是执行一直不会阻塞的运算操作。前者时断时续地占用CPU，而后者对CPU具有更高的利用率。预计完成任务大概需要多长时间？是短时间任务还是长时间任务？
根据任务的特点，对任务进行分类，然后把不同类型的任务分别加入到不同线程池的工作队列中，这样可以根据任务的特点，分别调整每个线程池。
（4）调整线程池的大小。线程池的最佳大小主要取决于系统的可用CPU的数目，以及工作队列中任务的特点。假如在一个具有 N 个CPU的系统上只有一个工作队列，并且其中全部是运算性质（不会阻塞）的任务，那么当线程池具有 N 或 N+1 个工作线程时，一般会获得最大的 CPU 利用率。
（5）避免任务过载。服务器应根据系统的承载能力，限制客户并发连接的数目。当客户并发连接的数目超过了限制值，服务器可以拒绝连接请求，并友好地告知客户：服务器正忙，请稍后再试。


------------------------------------------------------------------------
最近在开发中遇到一个问题，就是如何判断远端服务器是否已经断开连接，如果断开那么需要重新连接。

首先想到socket类的方法isClosed()、isConnected()、isInputStreamShutdown()、 isOutputStreamShutdown()等，但经过试验并查看相关文档，这些方法都是本地端的状态，无法判断远端是否已经断开连接。

然后想到是否可以通过OutputStream发送一段测试数据，如果发送失败就表示远端已经断开连接，类似ping，但是这样会影响到正常的输出数据，远端无法把正常数据和测试数据分开。

最后又回到socket类，发现有一个方法sendUrgentData，查看文档后得知它会往输出流发送一个字节的数据，只要对方Socket的 SO_OOBINLINE属性没有打开，就会自动舍弃这个字节，而SO_OOBINLINE属性默认情况下就是关闭的，太好了，正是我需要的！

于是，下面一段代码就可以判断远端是否断开了连接：

try{
socket.sendUrgentData(0xFF);
}catch(Exception ex){
reconnect(); }

[心跳] 呢？
-----------------------------------------------------------------------

我们经常听说tcp协议的三次握手,但三次握手到底是什么，其细节是什么，为什么要这么做呢?
第一次:客户端发送连接请求给服务器，服务器接收;
第二次:服务器返回给客户端一个确认码,附带一个从服务器到客户端的连接请求,客户机接收,确认客户端到服务器的连接.
第三次:客户机返回服务器上次发送请求的确认码,服务器接收,确认服务器到客户端的连接.
我们可以看到:
1. tcp的每个连接都需要确认.
2. 客户端到服务器和服务器到客户端的连接是独立的.
我们再想想tcp协议的特点:连接的,可靠的,全双工的,实际上tcp的三次握手正是为了保证这些特性的实现.



IO重用技术有很多种，有些是夸平台的，有些是平台独有的，这里就列举一些我知道的：
名称 	平台
select 	Linux, *BSD, Mac OS X, Solaris, Windows
poll 	Linux, *BSD, Mac OS X
epoll 	Linux
/dev/poll 	Solaris
kqueue 	FreeBSD
IOCP 	Windows


http://blog.sina.com.cn/s/blog_494e45fe0100la5m.html

http://hi.baidu.com/wjtao291/blog/item/856746f03425e0aea40f52f9.html

http://www.cnblogs.com/jeriffe/articles/1721666.html

http://chenzhongke.com/wi/Python%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B



增大Linux的socket最大连接数

最近接的项目是模拟多个socket 客户端与服务器进行通信。由于Linux 系统的限制，在linux/include/linux/posix_types.h文件中有如下的宏定义：
#undef __FD_SETSIZE
#define __FD_SETSIZE 1024

这个宏是对最大文件描述符的定义为1024。当需要1024个以上的fd时，例如select()函数就会侦听出错。因此需要将1024改成需要的数目，但最多不能超过65535。但仅仅修改这个是不够的。
第二步就需要修改一个进程最大打开的文件数。其具体步骤是：
1、cd /usr/src/linux-2.4/include/linux
2、vi limits.h　编辑文件：
#define NR_OPEN 90240 原值为1024
#define OPEN_MAX 10240 原值为1024
3、vi fs.h
#define INR_OPEN 10240 原值为1024
#define NR_FILE 65536 原值为8192，这个值为内存64/1M的比率计算，1G内存计算为:64*1024
#define NR_RESERVED_FILES 128 原值为10.
4、cd /usr/src/linux-2.4/include/net
5、vi tcp.h
#define TCP_LHTABLE_SIZE 128 原值为32.便于listen侦听队列，设大。
设置最大打开文件数与内存相关，太大系统会变慢。

第三步就是编译内核，其具体步骤是：
1. make clean
2. make
3. make dep
4. make bzImage
将bzImage 导入/boot 重启系统即可!

用 1024个以上客户端与服务器进行连接，在服务器的终端用netstat |wc 命令可以统计出当前建立的socket的连接数


关于select
select I/O模型是一种异步I/O模型，在单线程中Linux/WinNT默认支持64个客户端套接字
用select支持多Client是比较方便的，在一个线程中可支持63个；可以采用多线程支持更大数量的Client


[转： 关于异步的那点事]  http://cmgs.me/blog/2010/08/about-async/
昨天公司Q3季度新员工培训，导致昨天实在是没精神来写Blog，只在WP里面建立了一个草稿。这个话题很早就想讨论了，主要是自己在金山的第一个项目就是密集型Web应用开发，而我们知道常规的process/thread模式很难承受客户端10K左右的压力，因此也出现了那一篇著名的论文《The C10K problem》，所以在这一块上有了点深入的认识。在这个过程之中我主要看了Nginx的部分源码和其构架，了解其运行模式等，顺带的也看Python界几个著名的异步服务框架，以及实现了基于IOCP/ePoll async I/O server。今天就总结一下最近的心得。

首先要说的是感谢nginx带来的服务器变革，在这之前Apache一统江湖，但带来的除了C10K Problem之外还有资源的大量浪费，这也是process/thread模型的弊端。之所以出现这个情况是因为每个Web请求带来了一个 blocking-I/O，如果想要将这个阻塞I/O变为非阻塞的，就必须开个线程来处理它。当然，在这个I/O没有完成的时候，这个thread无法做任何其他事情只能等待I/O完成，造成了线程的资源浪费。在这种模式下，整体上来看服务器是非阻塞的，但细分到线程就会发现其实还是阻塞的，再加上线程之间的切换带来的性能损耗（当然你可以说用线程池，但带来的就是庞大的软件体积和复杂度），因此传统模式的服务器构架到了一定程度就会遇到无法逾越的瓶颈了。Nginx的不同之处就在于它最大化利用了系统内核，利用系统内核的异步I/O接口如select，epoll，kqueue将I/O的操作交给了系统去做和维护，将前端Web服务从繁重的I/O中解脱了出来，轻松的使负载能力提高了数十倍，再通过事件机制（libevent）通知Web服务I/O什么时候完成，完成的时候激发一个事件通知Web服务响应，降低了系统的耦合。

说到nginx，必然就会说到epoll，kqueue，select等，因为nginx的高性能和革新的构架也是基于利用了系统内核的这些东西。一般来说select存在于各种*nix系统和windows系列之中，性能是最低的，因为它是把阻塞放到了轮询之中，一直轮询看是否I/O完成，而且 select在linux上还有64的限制。因此在linux界中，出现了它的替代品，就是epoll，epoll本质上是一个reactor模型，采用回调函数（CallBack）来告知I/O就绪，注意是就绪并非完成，socket I/O就绪之后通知回调函数进行阻塞式的从内核copy数据到应用层，当然这个阻塞是无足轻重的，不影响其异步的本质。好在微软那些牛逼的人开发了一个最牛逼的异步I/O接口，即IOCP（I/O Completion Port，I/O完成端口），和epoll不同之处在于它连从内核copy数据到应用层的这一步阻塞都没有，是纯异步的，只因为windows的服务器特性实在是让人情何以堪，所以空有一身本领却少有人用，基本上都是自己写基于IOCP的服务器实现。

到实际开发这一块（一个潜在项目规划），我主要用的是Python，之前不打算安装linux系统，直接用C封装IOCP，但无奈问题很多，比如是直接封装服务器还是封装接口呢bla bla的，最后忍痛装上ubuntu，直接纯python了。Python这块牛逼的异步服务框架主要有Twisted，这个我看得少，老牌重量级框架（我对老的一向不感冒哎）。完了Facebook搞了个龙卷风Tornado，王2弟他们项目就是采用这个作为异步RPC服务的接入口，这个的话还是偏重量，灵活度不高。最后我把目标锁定在了曾经评测过的gevent。Gevent相对于其他框架首先在于足够精简，代码很简练，再者它的构架又进了一步，采用的是微线程来处理请求而非以往的process/thread模式。在微线程这一块Gevent是用的Greenlet库，一个基于Cpython的微线程实现，在事件处理机制那块用的是自己对于libevent的封装，底层I/O在Linux下是epoll……

当然这些都是虚的，傻逼一样的select也被java整成了牛逼的nio，最后还是得看人的实现。来公司大半个月了，也是时候整点自己的东西了



[转 C10K问题和Libevent库介绍] http://mycbc.cn/cmmb/bbs/viewthread.php?tid=1358
一．C10K的问题

C10K的问题在上个世纪90年代就被提出来了。大概的意思是当用户数超过1万时，很多设计不良好的网络服务程序性能都将急剧下降、甚至瘫痪。并且，这个问题并不能通过升级硬件设备解决，是操作系统固有的问题，也就是说，如果你的服务器最高能支撑1000个并发，尽管你升级了计算能力高一倍的 cpu，内存再翻一番，硬盘转速在快一倍，也无法支撑2000个并发。

经典的网络编程模型有4个：

1. Serve one client with each thread/process, and use blocking I/O。即对每个客户都使用不同的线程或进程进行服务，在每个线程或进程中使用阻塞I/O。这是小程序和java常用的策略，对于交互式的应用也是常见的选择，这种策略很能难满足高性能程序的需求，好处是实现极其简单，容易实现复杂的交互逻辑。我们常用的Apache、ftpd等都是这种工作。

2. Serve many clients with single thread, and use nonblocking I/O and readiness notification。即对所有的客户使用单一一个线程或进程进行服务，在这个线程或进程里，采用异步IO的策略。这是经典模型，优点在于实现较简单，方便移植，也能提供足够的性能；缺点在于无法充分利用多CPU的资源。

3. Serve many clients with each thread, and use nonblocking I/O and readiness notification 对经典模型2的简单改进，仍然采用异步IO的策略，但对所有的客户使用多个线程或进程进行服务。缺点是容易在多线程并发上出bug，甚至某些OS不支持多线程进行readiness notification

4. Serve many clients with each thread, and use asynchronous I/O 在有AI/O支持的OS上，能提供相当高的性能。不过AI/O编程模型和经典模型差别相当大，基本上很难写出一个框架同时支持AI/O和经典模型。这个模型主要是用于window平台上。

在linux上开发高性能的网络应用，只能选着第2、3种方式。考虑到复杂性，我们往往只采用第2种。下面就讨论一下第二种模型。

我们知道，实现异步IO一般是采用select 或poll来实现。Select 定义如下：
int select(int n, fd_set *rd_fds, fd_set *wr_fds, fd_set *ex_fds, struct timeval *timeout);
Poll 的接口如下：
int poll(struct pollfd *ufds, unsigned int nfds, int timeout);

然而 Select 和Poll 在连接数增加时，性能急剧下降。这有两方面的原因：首先操作系统面对每次的select/poll 操作，都需要重新建立一个当前线程的关心事件列表，并把线程挂在这个复杂的等待队列上，这是相当耗时的。其次，应用软件在select/poll 返回后也需要对传入的句柄列表做一次扫描来判断哪些句柄是可用的，这也是很耗时的。这两件事都是和并发数相关，而I/O 事件的密度也和并发数相关，导致CPU 占用率和并发数近似成O(n2)的关系。

因为以上的原因，Unix 上开发了性能更高的epoll, kqueue, /dev/poll 这3个程序接口来解决上述问题。其中epoll 是linux 的方案，kqueue 是freebsd 的方案，/dev/poll 是最古老的Solaris 的方案，使用难度依次递增。

简单的说，这些api 做了两件事：
1. 避免了每次调用select/poll 时kernel 分析参数建立事件等待结构的开销，kernel 维护一个长期的事件关注列表，应用程序通过句柄修改这个列表和捕获I/O 事件。
2. 避免了select/poll 返回后，应用程序扫描整个句柄表的开销，Kernel 直接返回具体的事件列表给应用程序。


二. libevent库
由于epoll, kqueue, /dev/poll每个接口都有自己的特点，程序移植非常困难，于是需要对这些接口进行封装，以让它们易于使用和移植，其中libevent库就是其中之一。

按照libevent的官方网站，libevent库提供了以下功能：当一个文件描述符的特定事件（如可读，可写或出错）发生了，或一个定时事件发生了，libevent就会自动执行用户指定的回调函数，来处理事件。目前，libevent已支持以下接口/dev/poll, kqueue(2), event ports, select(2), poll(2) 和 epoll(4)。Libevent的内部事件机制完全是基于所使用的接口的。因此libevent非常容易移植，也使它的扩展性非常容易。目前，libevent已在以下操作系统中编译通过：Linux，BSD，Mac OS X，Solaris和Windows。

使用libevent库进行开发非常简单，也很容易在各种unix平台上移植。一个简单的使用libevent库的程序如下：

   

三．libevent库的应用

Go2代理是一个大流量的代理应用，月流量近TB。其中图片、flash、zip文件占总流量的绝大部分。为了减少流量成本，需要将部分进行分流。开始时，使用了传统的php代理来分流，但Go2并发访问极大，多进程架构的php无法承受，在虚拟主机vps上启动数秒后就立即瘫痪。后改用 python的twisted网络架构，采用了twisted的异步tcp通讯功能。运行一段时间后，发现twisted的异步dns稳定性不太好，经常发生系统级的崩溃。最后，经过分析比较，决定采用libevent库来做Go2 的分流代理应用。

Libevent库支持异步socket，支持异步dns，并本身还带了个简单的http 服务器。Go2 的分流代理应用就是使用了libevent库的以上三个功能。
1、简单的http 服务器：实现的分类代理的用户端的输入，输出管理。
2、异步socket，实现了高并发性的用户接入，和高并发性的目的服务器访问。
3、异步dns，解决了dns查询时的并发性和高效性。

下面简单介绍一下Go2 的分流代理程序的主要流程。源代码请参考http://bbs.mycbc.cn/upload/bbs/viewthread.php?tid=601&extra=page%3D1

A.      主程序流程
1、使用event_init()初始化libevent环境；
2、使用evhttp_new()生成http服务实例，并使用evhttp_bind_socket聆听指定的端口；
3、使用evhttp_set_cb设置http服务实例的url回调函数。
4、进入libevent的事件循环。每当有用户请求url，libevent将自动调用url所对应的回调函数。

B.      用户请求处理流程：
1、Libevent监控到用户url访问请求，libevent调用自定义的回调函数。
2、对用户最终访问的url进行base64解码操作，获取到用户访问的目的URL。
3、检查目的URL是否合法，非法，则结束。
4、URL合法，检查是否有本地缓存，有，直接从本地缓存获取数据，返回，并结束。
5、没有本地缓存，则通过libevent的异步dns查询api 对目的域名进行解释，并设置解释完成后的回调函数。Api原型：evdns_resolve_ipv4(host, 0, http_dns_cb, req)，其中host是域名, http_dns_cb是解释完成后的回调函数。
6、在回调函数http_dns_cb中，完成以下操作：
a) 使用libevent异步socket连接到指定的服务器，并通过监控socket是否可写来判断连接是否成功。通过设置监听socket写事件来完成这个功能：event_set (&req-"proxyev, socket, EV_WRITE, my_connect_cb, req )，其中参数EV_WRITE告诉libevent，只监控socket的可写事件；my_connect_cb是事件发生后的回调函数。
b) 在my_connect_cb函数中，通过监控socket的可读事件，来获取服务器返回的数据：event_set(&req-"proxyev, socket, EV_READ, my_read_cb, req )，其中参数EV_READ是告诉libevent只监控socket的可读事件；my_read_cb是当可读事件发生后的回调函数。
c) my_read_cb回调函数则是核心的数据处理函数。负责从服务器中获取数据，并将数据返回给用户。

7、将图片缓存到本地，结束。
Go2 的分流代理在实际应用中，每分钟能处理3000个请求，月流量近TB，而应用则是跑在一台低端的vps上。

参考文档：
1、C10K问题---epoll简介，搜狗实验室， http://www.sogou.com/labs/report/1-1.pdf
2、The C10K problem（英文），http://www.kegel.com/c10k.html
3、libevent 官方网站，http://www.monkey.org/~provos/libevent/
